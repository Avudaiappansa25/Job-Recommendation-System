{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93298c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "\n",
    "def tokenize_stem(series):\n",
    "\n",
    "    tokenizer =TreebankWordTokenizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    series = series.apply(lambda x: x.replace(\"\\n\", ' '))\n",
    "    series = series.apply(lambda x: tokenizer.tokenize(x))\n",
    "    series = series.apply(lambda x: [stemmer.stem(w) for w in x])\n",
    "    series = series.apply(lambda x: ' '.join(x))\n",
    "    return series\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    '''\n",
    "    displays topics and returns list of toppics\n",
    "    '''\n",
    "\n",
    "    topic_list = []\n",
    "    for i, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[i]:\n",
    "            print(\"\\nTopic \", i)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[i],\"'\")\n",
    "\n",
    "        print(\", \".join([feature_names[k]\n",
    "                       for k in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        topic_list.append(\", \".join([feature_names[k]\n",
    "                       for k in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "    return model.components_, topic_list\n",
    "\n",
    "def return_topics(series, num_topics, no_top_words, model, vectorizer):\n",
    "    '''\n",
    "    returns document_topic matrix and topic modeling model\n",
    "    '''\n",
    "    #turn job into series\n",
    "    series = tokenize_stem(series)\n",
    "    #transform series into corpus\n",
    "    ex_label = [e[:30]+\"...\" for e in series]\n",
    "    #set vectorizer ngrams = (2,2)\n",
    "    vec = vectorizer(stop_words = 'english')\n",
    "\n",
    "    doc_word = vec.fit_transform(series)\n",
    "\n",
    "    #build model\n",
    "    def_model = model(num_topics)\n",
    "    def_model = def_model.fit(doc_word)\n",
    "    doc_topic = def_model.transform(doc_word)\n",
    "    #print('model components: ', def_model.components_[0].shape)\n",
    "    #print('doc_topic', doc_topic[0])\n",
    "    model_components, topic_list = display_topics(def_model, vec.get_feature_names(), no_top_words)\n",
    "    return def_model.components_, doc_topic, def_model, vec, topic_list#, topics\n",
    "\n",
    "\n",
    "def process_data():\n",
    "    '''\n",
    "    uses the functions above to read in files, model, and return a topic_document dataframe\n",
    "    '''\n",
    "    #read in jobs file and get descriptions\n",
    "    df = pd.read_csv('D:/Job_Recommender/ML_Project.csv')\n",
    "    #df = df[df.keyword!='marketing']\n",
    "    jobs_df = pd.DataFrame(zip(df['Job Description'], df['keyword']), columns = ['Description', 'Job'])\n",
    "\n",
    "    array, doc, topic_model, vec, topic_list  = return_topics(jobs_df['Description'],20, 10, TruncatedSVD, TfidfVectorizer)\n",
    "\n",
    "    topic_df = pd.DataFrame(doc)\n",
    "    topic_df.columns = ['Topic ' + str(i+1) for i in range(len(topic_df.columns)) ]\n",
    "\n",
    "    topic_df['job'] = jobs_df.Job\n",
    "    #topic_df.to_csv('D:/Job_Recommender/topic_df2.csv')\n",
    "    resume=\"Data enthusisast\\n who is keen to work and do progress with capabilities of machine learning\"\n",
    "    resume=list(resume)\n",
    "    resume = pd.Series(resume)\n",
    "    doc = tokenize_stem(resume)\n",
    "    doc = vec.transform(doc)\n",
    "    #topic_model_name = 'D:/Job_Recommender/topic_model1.sav'\n",
    "    #pickle.dump(topic_model, open(topic_model_name, 'wb'))\n",
    "    vec_name = 'D:/Job_Recommender/job_vec1.sav'\n",
    "    pickle.dump(vec, open(vec_name, 'wb'))\n",
    "    return topic_df, topic_model, vec, topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736e6fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "charlott, deloitt, consult, scienc, data, ventur, red, lowe, senior, connect\n",
      "\n",
      "Topic  1\n",
      "data, tool, analyt, nc, scientist, year, experi, variou, serv, creat\n",
      "\n",
      "Topic  2\n",
      "variou, experi, year, valid, opportun, identifi, clean, optimizations, set, sourc\n",
      "\n",
      "Topic  3\n",
      "scientist, need, futur, lead, becom, skill, ll, narr, mining, discov\n",
      "\n",
      "Topic  4\n",
      "data, busi, perform, narr, told, explor, present, discov, mining, nc\n",
      "\n",
      "Topic  5\n",
      "work, year, experi, nc, relev, machin, learn, consult, team, requir\n",
      "\n",
      "Topic  6\n",
      "candid, technolog, appli, knowledg, manag, projects, autom, cognit, help, nc\n",
      "\n",
      "Topic  7\n",
      "collabor, product, cross, funct, manipul, access, team, applic, data, scienc\n",
      "\n",
      "Topic  8\n",
      "consult, deloitt, collabor, industri, product, funct, manipul, cross, access, work\n",
      "\n",
      "Topic  9\n",
      "consult, scienc, deloitt, data, ventur, red, senior, industri, lowe, engin\n",
      "\n",
      "Topic  10\n",
      "design, engin, nc, architectur, integr, process, compil, develop, requir, shadow\n",
      "\n",
      "Topic  11\n",
      "engin, work, avail, enrich, model, train, relev, team, job, dedic\n",
      "\n",
      "Topic  12\n",
      "big, learn, data, deep, engin, analysi, incumb, machine, method, machin\n",
      "\n",
      "Topic  13\n",
      "engin, red, ventur, servic, financi, connect, machin, applic, evalu, latest\n",
      "\n",
      "Topic  14\n",
      "engin, financi, use, senior, report, abil, manag, profici, strong, level\n",
      "\n",
      "Topic  15\n",
      "intern, shadow, machin, learn, subject, matter, close, serv, financi, compil\n",
      "\n",
      "Topic  16\n",
      "requir, ventur, red, compil, connect, nc, shadow, intern, servic, familiar\n",
      "\n",
      "Topic  17\n",
      "requir, big, scienc, industry, translat, fort, lpl, advanc, method, machine\n",
      "\n",
      "Topic  18\n",
      "requir, compil, stakehold, provid, applic, nc, self, start, deep, familiar\n",
      "\n",
      "Topic  19\n",
      "credit, safeti, karma, trust, wholesal, thi, role, report, close, senior\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avuda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     Topic 1   Topic 2   Topic 3   Topic 4   Topic 5   Topic 6   Topic 7  \\\n",
       " 0   0.021822  0.389852  0.826392  0.091642 -0.331294 -0.192427 -0.028135   \n",
       " 1   0.026414  0.464419 -0.380196  0.661692 -0.354254  0.138416  0.029508   \n",
       " 2   0.984186 -0.077162 -0.003351  0.003044 -0.028155 -0.030386  0.005283   \n",
       " 3   0.013808  0.239761  0.270393 -0.077069  0.050714  0.427555 -0.141673   \n",
       " 4   0.005876  0.103392  0.046249 -0.053524  0.068137  0.115412  0.074789   \n",
       " ..       ...       ...       ...       ...       ...       ...       ...   \n",
       " 61  0.021822  0.389852  0.826392  0.091642 -0.331294 -0.192427 -0.028135   \n",
       " 62  0.023338  0.419692 -0.356365  0.639826 -0.345047  0.142590  0.031244   \n",
       " 63  0.038391  0.657445 -0.371126 -0.534549 -0.310064 -0.167776  0.007040   \n",
       " 64  0.505384 -0.031343  0.009195 -0.008137  0.005115  0.138552  0.022094   \n",
       " 65  0.452382 -0.013792  0.014948 -0.014776  0.015216  0.172789  0.022855   \n",
       " \n",
       "      Topic 8   Topic 9  Topic 10  ...  Topic 12  Topic 13  Topic 14  Topic 15  \\\n",
       " 0   0.041064  0.044070  0.038821  ... -0.002272 -0.010567 -0.007004  0.000561   \n",
       " 1   0.039715  0.002643 -0.003677  ... -0.015814  0.002220  0.006450  0.022465   \n",
       " 2   0.013549 -0.004443 -0.111096  ...  0.055153 -0.000237 -0.033497  0.010595   \n",
       " 3  -0.144309 -0.126562 -0.381807  ... -0.170986  0.173966  0.149076  0.079073   \n",
       " 4  -0.062246  0.085893 -0.113891  ... -0.413710 -0.186280 -0.055483  0.010702   \n",
       " ..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       " 61  0.041064  0.044070  0.038821  ... -0.002272 -0.010567 -0.007004  0.000561   \n",
       " 62  0.043339  0.002937 -0.004107  ... -0.019046  0.002486  0.008185  0.029029   \n",
       " 63 -0.030931  0.061711 -0.013891  ...  0.021077 -0.045596  0.063048 -0.027343   \n",
       " 64 -0.271203  0.481398  0.429738  ... -0.185336  0.136758  0.031222  0.069046   \n",
       " 65 -0.289496  0.475455  0.445269  ... -0.214711  0.112241 -0.007407  0.150907   \n",
       " \n",
       "     Topic 16  Topic 17  Topic 18  Topic 19  Topic 20  \\\n",
       " 0   0.011785  0.014728  0.014676 -0.024316 -0.004611   \n",
       " 1   0.014585  0.002593  0.001895 -0.012045 -0.005567   \n",
       " 2   0.009318 -0.020264  0.000819  0.023580 -0.030057   \n",
       " 3   0.213689 -0.032179 -0.029891  0.019774  0.024274   \n",
       " 4  -0.072447 -0.131552 -0.068991 -0.179557 -0.088523   \n",
       " ..       ...       ...       ...       ...       ...   \n",
       " 61  0.011785  0.014728  0.014676 -0.024316 -0.004611   \n",
       " 62  0.019489  0.003853  0.003118 -0.016902 -0.007599   \n",
       " 63  0.004003 -0.012408  0.024697  0.019143  0.004328   \n",
       " 64  0.073960 -0.042163 -0.013971 -0.079783 -0.000441   \n",
       " 65  0.011879 -0.011234  0.004791 -0.022843  0.069633   \n",
       " \n",
       "                                                job  \n",
       " 0                                   Data Scientist  \n",
       " 1                                  Data Scienctist  \n",
       " 2                                 Data Scientist\\t  \n",
       " 3                                 Data Scientist\\t  \n",
       " 4                                 Data Scientist\\t  \n",
       " ..                                             ...  \n",
       " 61                                Data Scientist\\t  \n",
       " 62       Data Science Fellow\\tThe Data Incubator\\t  \n",
       " 63                      Actuarial Data Scientist\\t  \n",
       " 64  Azure Cloud Enablement - Analytics & Cognitive  \n",
       " 65  Azure Cloud Enablement - Analytics & Cognitive  \n",
       " \n",
       " [66 rows x 21 columns],\n",
       " TruncatedSVD(n_components=20),\n",
       " TfidfVectorizer(stop_words='english'),\n",
       " ['charlott, deloitt, consult, scienc, data, ventur, red, lowe, senior, connect',\n",
       "  'data, tool, analyt, nc, scientist, year, experi, variou, serv, creat',\n",
       "  'variou, experi, year, valid, opportun, identifi, clean, optimizations, set, sourc',\n",
       "  'scientist, need, futur, lead, becom, skill, ll, narr, mining, discov',\n",
       "  'data, busi, perform, narr, told, explor, present, discov, mining, nc',\n",
       "  'work, year, experi, nc, relev, machin, learn, consult, team, requir',\n",
       "  'candid, technolog, appli, knowledg, manag, projects, autom, cognit, help, nc',\n",
       "  'collabor, product, cross, funct, manipul, access, team, applic, data, scienc',\n",
       "  'consult, deloitt, collabor, industri, product, funct, manipul, cross, access, work',\n",
       "  'consult, scienc, deloitt, data, ventur, red, senior, industri, lowe, engin',\n",
       "  'design, engin, nc, architectur, integr, process, compil, develop, requir, shadow',\n",
       "  'engin, work, avail, enrich, model, train, relev, team, job, dedic',\n",
       "  'big, learn, data, deep, engin, analysi, incumb, machine, method, machin',\n",
       "  'engin, red, ventur, servic, financi, connect, machin, applic, evalu, latest',\n",
       "  'engin, financi, use, senior, report, abil, manag, profici, strong, level',\n",
       "  'intern, shadow, machin, learn, subject, matter, close, serv, financi, compil',\n",
       "  'requir, ventur, red, compil, connect, nc, shadow, intern, servic, familiar',\n",
       "  'requir, big, scienc, industry, translat, fort, lpl, advanc, method, machine',\n",
       "  'requir, compil, stakehold, provid, applic, nc, self, start, deep, familiar',\n",
       "  'credit, safeti, karma, trust, wholesal, thi, role, report, close, senior'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c4e8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_modeling(df):\n",
    "    '''\n",
    "    fits, optimizes, and predicts job class based on topic modeling corpus\n",
    "    '''\n",
    "    X,y = df.iloc[:,0:-1], df.iloc[:, -1]\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    param_grid = {'n_estimators': [100,200,300,400,500], 'max_depth': [3,7,9, 11]}\n",
    "    #search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "    #search.fit(X_tr, y_tr)\n",
    "    #bp = search.best_params_\n",
    "    #print(bp)\n",
    "    #rfc = RandomForestClassifier(n_estimators = bp['n_estimators'], max_depth = bp['max_depth'])\n",
    "    rfc = RandomForestClassifier(n_estimators =3500, max_depth = 10)\n",
    "    rfc.fit(X_tr, y_tr)\n",
    "    print('acc: ', np.mean(cross_val_score(rfc, X_tr, y_tr, scoring = 'accuracy', cv=5)))\n",
    "    print('test_acc: ', accuracy_score(y_te, rfc.predict(X_te)))\n",
    "    print(rfc.predict(X_te))\n",
    "    return rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de96dea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturial,data,scientist\\t    22\n",
      "data,analytics               26\n",
      "data,scientist               27\n",
      "senior,data,scientist\\t      27\n",
      "ai,ml,developer\\t            30\n",
      "Name: job, dtype: int64\n",
      "acc:  0.7333333333333334\n",
      "test_acc:  0.9259259259259259\n",
      "['ai,ml,developer\\t' 'ai,ml,developer\\t' 'ai,ml,developer\\t'\n",
      " 'ai,ml,developer\\t' 'ai,ml,developer\\t' 'ai,ml,developer\\t'\n",
      " 'ai,ml,developer\\t' 'ai,ml,developer\\t' 'ai,ml,developer\\t'\n",
      " 'ai,ml,developer\\t' 'ai,ml,developer\\t' 'ai,ml,developer\\t'\n",
      " 'ai,ml,developer\\t' 'ai,ml,developer\\t' 'ai,ml,developer\\t'\n",
      " 'data,analytics' 'data,analytics' 'data,analytics' 'data,analytics'\n",
      " 'data,analytics' 'data,analytics' 'data,analytics' 'data,analytics'\n",
      " 'data,analytics' 'data,analytics' 'data,analytics' 'data,analytics']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, n_estimators=3500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, n_estimators=3500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=3500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"D:/Job_Recommender/topic_df2.csv\")\n",
    "\n",
    "print(df['job'].value_counts(ascending=True))\n",
    "predictive_modeling(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469ff77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
